name: WhatsApp AI Bot - Enhanced Deployment

on:
  schedule:
    # Run every 5 hours to maintain session
    - cron: '0 */5 * * *'
  workflow_dispatch:
    inputs:
      force_restart:
        description: 'Force restart the bot'
        required: false
        default: 'false'
  push:
    branches: [ main ]

jobs:
  deploy-whatsapp-bot:
    runs-on: ubuntu-latest
    timeout-minutes: 290  # Just under 5 hours
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Free Disk Space - Remove Unnecessary Packages
      run: |
        echo "🧹 Freeing up disk space for AI models..."
        df -h
        
        # Remove large packages that aren't needed
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL
        sudo rm -rf /usr/local/share/boost
        sudo rm -rf /usr/local/graalvm/
        sudo rm -rf /usr/local/.ghcup/
        sudo rm -rf /usr/local/share/powershell
        sudo rm -rf /usr/local/share/chromium
        sudo rm -rf /usr/local/lib/node_modules
        sudo rm -rf /usr/share/swift
        sudo rm -rf /usr/local/julia*
        sudo rm -rf /usr/share/az_*
        
        # Remove specific packages
        sudo apt-get remove -y '^dotnet-.*' '^llvm-.*' 'php.*' 'mysql-*' 'mongodb-*'
        sudo apt-get remove -y azure-cli google-cloud-sdk firefox
        sudo apt-get autoremove -y
        sudo apt-get autoclean -y
        
        # Clean package cache
        sudo apt-get clean
        sudo rm -rf /var/lib/apt/lists/*
        
        # Clean Docker if present
        docker system prune -af || true
        
        echo "📊 Disk space after cleanup:"
        df -h

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Set up Node.js for WhatsApp Bridge
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Cache Python Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install System Dependencies
      run: |
        echo "🔧 Installing system dependencies..."
        sudo apt-get update
        sudo apt-get install -y \
          ffmpeg \
          espeak \
          espeak-data \
          libespeak1 \
          libespeak-dev \
          festival \
          sox \
          libsox-fmt-mp3 \
          flac \
          pulseaudio \
          alsa-utils \
          git-lfs
          
    - name: Install Python Dependencies with Streaming Optimization
      run: |
        echo "🐍 Installing Python dependencies for streaming AI..."
        pip install --upgrade pip wheel setuptools
        
        # Install core dependencies first
        pip install \
          requests \
          beautifulsoup4 \
          trafilatura \
          python-dotenv \
          gtts \
          speechrecognition \
          pydub \
          pillow \
          psutil \
          asyncio-mqtt
        
        # Install PyTorch CPU version for streaming (no GPU needed)
        pip install torch==2.1.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
        
        # Install transformers with streaming support
        pip install \
          transformers[torch] \
          accelerate \
          tokenizers \
          datasets \
          sentencepiece \
          protobuf
        
        # Install additional AI/ML tools for enhanced features
        pip install \
          scipy \
          numpy \
          scikit-learn \
          nltk \
          googletrans==4.0.0rc1
          
        echo "📦 Python dependencies installed successfully"

    - name: Install Node.js Dependencies for WhatsApp
      run: |
        echo "📦 Installing Node.js dependencies..."
        npm install --production \
          @whiskeysockets/baileys \
          @hapi/boom \
          qrcode-terminal \
          pino
        echo "✅ Node.js dependencies installed"

    - name: Setup Environment Variables
      run: |
        echo "🔧 Setting up environment variables..."
        echo "GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}" >> $GITHUB_ENV
        echo "PYTHON_UNBUFFERED=1" >> $GITHUB_ENV
        echo "TOKENIZERS_PARALLELISM=false" >> $GITHUB_ENV
        echo "HF_HOME=/tmp/huggingface" >> $GITHUB_ENV
        echo "TRANSFORMERS_CACHE=/tmp/transformers" >> $GITHUB_ENV
        echo "TORCH_HOME=/tmp/torch" >> $GITHUB_ENV

    - name: Deploy Whoogle Search Instance
      run: |
        echo "🔍 Setting up Whoogle search instance..."
        # Install Whoogle dependencies
        pip install whoogle-search
        
        # Start Whoogle in background
        nohup python -m whoogle &
        WHOOGLE_PID=$!
        echo "WHOOGLE_PID=$WHOOGLE_PID" >> $GITHUB_ENV
        
        # Wait for Whoogle to start
        sleep 10
        
        # Test Whoogle connection
        curl -s http://localhost:5000 > /dev/null && echo "✅ Whoogle search deployed successfully" || echo "⚠️ Whoogle may not be ready yet"

    - name: Initialize AI Models with Streaming
      run: |
        echo "🧠 Initializing AI models with streaming optimization..."
        
        # Create model initialization script
        cat > init_models.py << 'EOF'
        import os
        import gc
        import torch
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        print("🔄 Pre-loading AI models for streaming...")
        
        # Set environment for streaming
        os.environ['TOKENIZERS_PARALLELISM'] = 'false'
        
        try:
            # Load lightweight conversational model
            model_name = "microsoft/DialoGPT-small"
            print(f"📥 Streaming model: {model_name}")
            
            # Stream tokenizer (lightweight)
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            print("✅ Tokenizer loaded")
            
            # Stream model with memory optimization
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float32,
                low_cpu_mem_usage=True,
                device_map=None,  # Force CPU
                cache_dir=None  # Don't cache in GitHub Actions
            )
            print("✅ Model loaded with streaming optimization")
            
            # Test model functionality
            test_input = tokenizer.encode("Hello", return_tensors="pt")
            with torch.no_grad():
                output = model.generate(test_input, max_length=20, do_sample=True)
            response = tokenizer.decode(output[0], skip_special_tokens=True)
            print(f"🧪 Model test: {response}")
            
            # Clean up for memory efficiency
            del model, tokenizer, test_input, output
            gc.collect()
            print("🧹 Memory cleaned after model test")
            
        except Exception as e:
            print(f"⚠️ Model initialization warning: {e}")
            print("🔄 Bot will use fallback responses if needed")
        EOF
        
        python init_models.py

    - name: Create WhatsApp Credentials
      run: |
        echo "🔐 Setting up WhatsApp credentials..."
        
        # Create credentials directory
        mkdir -p wa-auth
        
        # Use provided credentials if available
        if [ -n "${{ secrets.WHATSAPP_CREDS }}" ]; then
          echo '${{ secrets.WHATSAPP_CREDS }}' > wa-auth/creds.json
          echo "✅ WhatsApp credentials configured from secrets"
        else
          echo "⚠️ No WhatsApp credentials found in secrets"
          echo "📱 Bot will generate QR code for first-time setup"
        fi

    - name: Create Enhanced Configuration
      run: |
        echo "⚙️ Creating enhanced bot configuration..."
        
        cat > .env << 'EOF'
        # WhatsApp AI Bot Enhanced Configuration
        BOT_NAME=Enhanced AI Assistant 🤖
        BOT_PREFIX=!
        
        # AI Model Configuration (Streaming Optimized)
        AI_MODEL=microsoft/DialoGPT-small
        MAX_RESPONSE_LENGTH=300
        TEMPERATURE=0.8
        USE_STREAMING=true
        
        # Enhanced Personality Settings
        PERSONALITY_MODE=take_charge_humorous
        HUMOR_LEVEL=high
        TAKE_CHARGE_ATTITUDE=true
        INTERACTION_STYLE=engaging
        JOKE_FREQUENCY=0.4
        PROACTIVE_MESSAGING=true
        
        # Voice Processing (Enhanced)
        VOICE_ENABLED=true
        TTS_LANGUAGE=en
        VOICE_SPEED=1.0
        VOICE_CLONING=false
        
        # Web Search Configuration
        WHOOGLE_URL=http://localhost:5000
        SEARCH_ENABLED=true
        MAX_SEARCH_RESULTS=5
        
        # Auto-Reply System (Enhanced)
        AUTO_REPLY_ENABLED=false
        AUTO_REPLY_DELAY_MIN=3
        AUTO_REPLY_DELAY_MAX=10
        LEARNING_MODE=true
        
        # Feature Toggles (All Enhanced Features)
        MEME_GENERATION=true
        ASCII_ART=true
        TRANSLATION=true
        CHAT_ANALYSIS=true
        STORY_GENERATION=true
        VOICE_CLONING=false
        PROACTIVE_SUGGESTIONS=true
        
        # Performance Optimization
        CACHE_SIZE=200
        MAX_HISTORY_LENGTH=30
        MEMORY_CLEANUP_INTERVAL=300
        
        # GitHub Actions Specific
        GITHUB_ACTIONS=true
        ENVIRONMENT=production
        LOG_LEVEL=INFO
        EOF
        
        echo "✅ Enhanced configuration created"

    - name: Start WhatsApp Bridge (Node.js)
      run: |
        echo "🌉 Starting WhatsApp bridge..."
        
        # Create enhanced WhatsApp bridge
        cat > whatsapp_bridge_enhanced.js << 'EOF'
        const { makeWASocket, DisconnectReason, useMultiFileAuthState } = require('@whiskeysockets/baileys');
        const { Boom } = require('@hapi/boom');
        const P = require('pino');
        const fs = require('fs');
        const path = require('path');
        
        class EnhancedWhatsAppBridge {
            constructor() {
                this.sock = null;
                this.connected = false;
                this.messageQueue = [];
                this.sessionData = {};
                this.reconnectAttempts = 0;
                this.maxReconnectAttempts = 10;
            }
        
            async initialize() {
                try {
                    console.log('🚀 Initializing Enhanced WhatsApp connection...');
                    
                    const authDir = './wa-auth';
                    if (!fs.existsSync(authDir)) {
                        fs.mkdirSync(authDir);
                    }
        
                    const { state, saveCreds } = await useMultiFileAuthState(authDir);
        
                    this.sock = makeWASocket({
                        auth: state,
                        logger: P({ level: 'silent' }),
                        printQRInTerminal: true,
                        defaultQueryTimeoutMs: 60000,
                        connectTimeoutMs: 60000,
                        keepAliveIntervalMs: 30000,
                        markOnlineOnConnect: true,
                    });
        
                    this.sock.ev.on('creds.update', saveCreds);
                    this.sock.ev.on('connection.update', (update) => this.handleConnectionUpdate(update));
                    this.sock.ev.on('messages.upsert', async (m) => await this.handleMessages(m));
        
                    console.log('✅ Enhanced WhatsApp bridge initialized');
        
                } catch (error) {
                    console.error('❌ Failed to initialize WhatsApp bridge:', error);
                    this.scheduleReconnect();
                }
            }
        
            handleConnectionUpdate(update) {
                const { connection, lastDisconnect, qr } = update;
                
                if (qr) {
                    console.log('📱 QR Code generated for WhatsApp Web');
                }
                
                if (connection === 'close') {
                    const shouldReconnect = (lastDisconnect?.error)?.output?.statusCode !== DisconnectReason.loggedOut;
                    console.log('🔌 Connection closed:', lastDisconnect?.error, '| Reconnecting:', shouldReconnect);
                    
                    if (shouldReconnect && this.reconnectAttempts < this.maxReconnectAttempts) {
                        this.scheduleReconnect();
                    } else {
                        console.log('🛑 Max reconnection attempts reached or logged out');
                    }
                } else if (connection === 'open') {
                    console.log('✅ Enhanced WhatsApp Web connected successfully!');
                    this.connected = true;
                    this.reconnectAttempts = 0;
                    this.notifyPython('connected');
                }
            }
        
            scheduleReconnect() {
                this.reconnectAttempts++;
                const delay = Math.min(5000 * this.reconnectAttempts, 30000);
                console.log(`🔄 Scheduling reconnect attempt ${this.reconnectAttempts} in ${delay}ms`);
                setTimeout(() => this.initialize(), delay);
            }
        
            async handleMessages(m) {
                try {
                    for (const msg of m.messages) {
                        if (!msg.message || msg.key.fromMe) continue;
                        
                        console.log('📨 Processing message:', msg.key.id);
                        
                        // Extract message content
                        const messageContent = this.extractMessageContent(msg);
                        
                        if (messageContent) {
                            // Send to Python backend for AI processing
                            await this.forwardToPython({
                                id: msg.key.id,
                                from: msg.key.remoteJid,
                                content: messageContent,
                                timestamp: Date.now(),
                                messageType: this.getMessageType(msg)
                            });
                        }
                    }
                } catch (error) {
                    console.error('❌ Error handling messages:', error);
                }
            }
        
            extractMessageContent(msg) {
                const message = msg.message;
                
                if (message.conversation) {
                    return message.conversation;
                } else if (message.extendedTextMessage) {
                    return message.extendedTextMessage.text;
                } else if (message.imageMessage) {
                    return message.imageMessage.caption || '[Image]';
                } else if (message.audioMessage) {
                    return '[Voice Message]';
                } else if (message.documentMessage) {
                    return `[Document: ${message.documentMessage.fileName || 'unknown'}]`;
                }
                
                return null;
            }
        
            getMessageType(msg) {
                const message = msg.message;
                if (message.conversation || message.extendedTextMessage) return 'text';
                if (message.imageMessage) return 'image';
                if (message.audioMessage) return 'audio';
                if (message.documentMessage) return 'document';
                return 'unknown';
            }
        
            async forwardToPython(messageData) {
                try {
                    // Create a simple file-based communication with Python
                    const queueFile = path.join(__dirname, 'message_queue.json');
                    let queue = [];
                    
                    if (fs.existsSync(queueFile)) {
                        const data = fs.readFileSync(queueFile, 'utf8');
                        queue = JSON.parse(data || '[]');
                    }
                    
                    queue.push(messageData);
                    fs.writeFileSync(queueFile, JSON.stringify(queue, null, 2));
                    
                    console.log('📤 Message forwarded to Python backend');
                } catch (error) {
                    console.error('❌ Error forwarding to Python:', error);
                }
            }
        
            async sendMessage(to, content, options = {}) {
                try {
                    if (!this.connected || !this.sock) {
                        console.log('⚠️ WhatsApp not connected, queuing message');
                        this.messageQueue.push({ to, content, options });
                        return;
                    }
        
                    let messageOptions = { text: content };
                    
                    // Add AI indicator
                    if (options.isAI) {
                        messageOptions.text = `🤖 ${content}`;
                    }
        
                    await this.sock.sendMessage(to, messageOptions);
                    console.log('✅ Message sent successfully');
                } catch (error) {
                    console.error('❌ Error sending message:', error);
                }
            }
        
            notifyPython(status) {
                try {
                    const statusFile = path.join(__dirname, 'whatsapp_status.json');
                    fs.writeFileSync(statusFile, JSON.stringify({
                        status: status,
                        timestamp: Date.now(),
                        connected: this.connected
                    }));
                } catch (error) {
                    console.error('❌ Error updating status:', error);
                }
            }
        
            async processOutgoingQueue() {
                const outgoingFile = path.join(__dirname, 'outgoing_queue.json');
                
                if (!fs.existsSync(outgoingFile)) return;
                
                try {
                    const data = fs.readFileSync(outgoingFile, 'utf8');
                    const queue = JSON.parse(data || '[]');
                    
                    for (const message of queue) {
                        await this.sendMessage(message.to, message.content, message.options);
                    }
                    
                    // Clear queue after processing
                    fs.writeFileSync(outgoingFile, '[]');
                } catch (error) {
                    console.error('❌ Error processing outgoing queue:', error);
                }
            }
        
            startQueueProcessor() {
                setInterval(() => {
                    this.processOutgoingQueue();
                }, 2000); // Check every 2 seconds
            }
        }
        
        // Initialize and start the enhanced bridge
        const bridge = new EnhancedWhatsAppBridge();
        bridge.initialize();
        bridge.startQueueProcessor();
        
        // Graceful shutdown
        process.on('SIGINT', () => {
            console.log('🛑 Shutting down Enhanced WhatsApp bridge...');
            bridge.notifyPython('disconnected');
            process.exit(0);
        });
        
        process.on('SIGTERM', () => {
            console.log('🛑 Terminating Enhanced WhatsApp bridge...');
            bridge.notifyPython('disconnected');
            process.exit(0);
        });
        EOF
        
        # Start the enhanced bridge in background
        nohup node whatsapp_bridge_enhanced.js &
        BRIDGE_PID=$!
        echo "BRIDGE_PID=$BRIDGE_PID" >> $GITHUB_ENV
        
        echo "✅ Enhanced WhatsApp bridge started (PID: $BRIDGE_PID)"

    - name: Start Enhanced WhatsApp AI Bot
      run: |
        echo "🤖 Starting Enhanced WhatsApp AI Bot..."
        
        # Create enhanced main runner
        cat > run_enhanced_bot.py << 'EOF'
        import asyncio
        import json
        import os
        import signal
        import sys
        import time
        import logging
        from pathlib import Path
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler('whatsapp_bot.log')
            ]
        )
        logger = logging.getLogger(__name__)
        
        class EnhancedWhatsAppBot:
            def __init__(self):
                self.running = True
                self.message_queue_file = Path('message_queue.json')
                self.outgoing_queue_file = Path('outgoing_queue.json')
                self.status_file = Path('whatsapp_status.json')
                
                # Initialize enhanced AI processor
                try:
                    from enhanced_ai_processor import EnhancedAIProcessor
                    from config import Config
                    
                    self.config = Config()
                    self.ai_processor = EnhancedAIProcessor(self.config)
                    logger.info("✅ Enhanced AI processor loaded")
                except Exception as e:
                    logger.error(f"❌ Failed to load enhanced components: {e}")
                    sys.exit(1)
            
            async def initialize(self):
                """Initialize the enhanced bot"""
                try:
                    logger.info("🚀 Initializing Enhanced WhatsApp AI Bot...")
                    
                    # Initialize AI models
                    await self.ai_processor.initialize_model()
                    
                    # Setup signal handlers
                    signal.signal(signal.SIGINT, self.signal_handler)
                    signal.signal(signal.SIGTERM, self.signal_handler)
                    
                    logger.info("✅ Enhanced WhatsApp AI Bot initialized")
                    
                except Exception as e:
                    logger.error(f"❌ Initialization failed: {e}")
                    raise
            
            def signal_handler(self, signum, frame):
                """Handle shutdown signals"""
                logger.info(f"📡 Received signal {signum}, shutting down...")
                self.running = False
            
            async def process_messages(self):
                """Process incoming messages from WhatsApp bridge"""
                if not self.message_queue_file.exists():
                    return
                
                try:
                    with open(self.message_queue_file, 'r') as f:
                        messages = json.load(f)
                    
                    if not messages:
                        return
                    
                    for message in messages:
                        await self.handle_message(message)
                    
                    # Clear processed messages
                    with open(self.message_queue_file, 'w') as f:
                        json.dump([], f)
                        
                except Exception as e:
                    logger.error(f"❌ Error processing messages: {e}")
            
            async def handle_message(self, message):
                """Handle individual message with enhanced AI"""
                try:
                    logger.info(f"🧠 Processing message from {message['from']}: {message['content'][:50]}...")
                    
                    # Generate AI response
                    response = await self.ai_processor.generate_response(
                        message['content'],
                        message['from'],
                        {'timestamp': message['timestamp']}
                    )
                    
                    # Queue response for sending
                    await self.queue_response(message['from'], response)
                    
                    logger.info(f"✅ Response generated and queued")
                    
                except Exception as e:
                    logger.error(f"❌ Error handling message: {e}")
                    # Send error response
                    await self.queue_response(
                        message['from'], 
                        "I'm experiencing some technical difficulties, but I'm still here! 🤖"
                    )
            
            async def queue_response(self, to, content):
                """Queue response for WhatsApp bridge to send"""
                try:
                    # Load existing queue
                    queue = []
                    if self.outgoing_queue_file.exists():
                        with open(self.outgoing_queue_file, 'r') as f:
                            queue = json.load(f)
                    
                    # Add new message
                    queue.append({
                        'to': to,
                        'content': content,
                        'options': {'isAI': True},
                        'timestamp': time.time()
                    })
                    
                    # Save queue
                    with open(self.outgoing_queue_file, 'w') as f:
                        json.dump(queue, f, indent=2)
                    
                except Exception as e:
                    logger.error(f"❌ Error queuing response: {e}")
            
            async def check_whatsapp_status(self):
                """Check WhatsApp bridge status"""
                if self.status_file.exists():
                    try:
                        with open(self.status_file, 'r') as f:
                            status = json.load(f)
                        
                        if status.get('status') == 'connected':
                            return True
                    except:
                        pass
                return False
            
            async def run(self):
                """Main bot loop"""
                try:
                    await self.initialize()
                    
                    logger.info("🔄 Starting enhanced bot main loop...")
                    
                    while self.running:
                        try:
                            # Process incoming messages
                            await self.process_messages()
                            
                            # Check WhatsApp status
                            connected = await self.check_whatsapp_status()
                            if not connected:
                                logger.warning("⚠️ WhatsApp bridge not connected")
                            
                            # Memory cleanup every 5 minutes
                            if int(time.time()) % 300 == 0:
                                import gc
                                gc.collect()
                                logger.info("🧹 Memory cleanup completed")
                            
                            # Small delay to prevent CPU overload
                            await asyncio.sleep(1)
                            
                        except Exception as e:
                            logger.error(f"❌ Error in main loop: {e}")
                            await asyncio.sleep(5)  # Wait before retrying
                    
                except Exception as e:
                    logger.error(f"❌ Fatal error in bot: {e}")
                    raise
                finally:
                    # Cleanup
                    logger.info("🧹 Cleaning up enhanced bot resources...")
                    await self.ai_processor.cleanup_resources()
        
        # Main execution
        if __name__ == "__main__":
            bot = EnhancedWhatsAppBot()
            try:
                asyncio.run(bot.run())
            except KeyboardInterrupt:
                logger.info("👋 Enhanced WhatsApp AI Bot stopped by user")
            except Exception as e:
                logger.error(f"💥 Fatal error: {e}")
                sys.exit(1)
        EOF
        
        # Start the enhanced bot
        nohup python run_enhanced_bot.py &
        BOT_PID=$!
        echo "BOT_PID=$BOT_PID" >> $GITHUB_ENV
        
        echo "✅ Enhanced WhatsApp AI Bot started (PID: $BOT_PID)"

    - name: Monitor and Maintain Session
      run: |
        echo "📊 Starting enhanced session monitoring..."
        
        # Create monitoring script
        cat > monitor_enhanced.py << 'EOF'
        import time
        import json
        import os
        import requests
        import psutil
        from pathlib import Path
        
        def check_process_health():
            """Check if bot processes are running"""
            bridge_pid = os.getenv('BRIDGE_PID')
            bot_pid = os.getenv('BOT_PID')
            whoogle_pid = os.getenv('WHOOGLE_PID')
            
            status = {
                'bridge': False,
                'bot': False,
                'whoogle': False,
                'timestamp': time.time()
            }
            
            try:
                if bridge_pid and psutil.pid_exists(int(bridge_pid)):
                    status['bridge'] = True
                
                if bot_pid and psutil.pid_exists(int(bot_pid)):
                    status['bot'] = True
                    
                if whoogle_pid and psutil.pid_exists(int(whoogle_pid)):
                    status['whoogle'] = True
            except:
                pass
            
            return status
        
        def check_whatsapp_connection():
            """Check WhatsApp connection status"""
            status_file = Path('whatsapp_status.json')
            if status_file.exists():
                try:
                    with open(status_file, 'r') as f:
                        status = json.load(f)
                    return status.get('connected', False)
                except:
                    pass
            return False
        
        def get_system_stats():
            """Get system resource usage"""
            return {
                'cpu_percent': psutil.cpu_percent(interval=1),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_usage': psutil.disk_usage('/').percent,
                'timestamp': time.time()
            }
        
        # Main monitoring loop
        start_time = time.time()
        max_runtime = 4.5 * 60 * 60  # 4.5 hours
        
        print("🔍 Enhanced monitoring started")
        
        while time.time() - start_time < max_runtime:
            try:
                # Check process health
                health = check_process_health()
                
                # Check WhatsApp connection
                wa_connected = check_whatsapp_connection()
                
                # Get system stats
                stats = get_system_stats()
                
                # Log status
                print(f"🤖 Bot Health: Bridge={health['bridge']}, Bot={health['bot']}, Whoogle={health['whoogle']}")
                print(f"📱 WhatsApp: Connected={wa_connected}")
                print(f"💻 System: CPU={stats['cpu_percent']:.1f}%, RAM={stats['memory_percent']:.1f}%, Disk={stats['disk_usage']:.1f}%")
                
                # Check message processing
                msg_queue = Path('message_queue.json')
                if msg_queue.exists():
                    with open(msg_queue, 'r') as f:
                        messages = json.load(f)
                    print(f"📨 Messages in queue: {len(messages)}")
                
                # Sleep for 30 seconds
                time.sleep(30)
                
            except Exception as e:
                print(f"❌ Monitoring error: {e}")
                time.sleep(60)
        
        print("⏰ Monitoring completed - approaching workflow timeout")
        EOF
        
        # Run monitoring
        python monitor_enhanced.py
        
    - name: Cleanup and Prepare for Next Run
      if: always()
      run: |
        echo "🧹 Cleaning up for next deployment cycle..."
        
        # Stop processes gracefully
        if [ -n "$BOT_PID" ]; then
          kill -TERM $BOT_PID || true
          echo "🛑 Bot process stopped"
        fi
        
        if [ -n "$BRIDGE_PID" ]; then
          kill -TERM $BRIDGE_PID || true
          echo "🛑 Bridge process stopped"
        fi
        
        if [ -n "$WHOOGLE_PID" ]; then
          kill -TERM $WHOOGLE_PID || true
          echo "🛑 Whoogle process stopped"
        fi
        
        # Clean temporary files but preserve auth
        rm -f message_queue.json outgoing_queue.json whatsapp_status.json
        rm -f whatsapp_bot.log
        
        # Clean AI model cache
        rm -rf /tmp/huggingface /tmp/transformers /tmp/torch
        
        echo "✅ Cleanup completed - ready for next cycle"

    - name: Generate Deployment Report
      if: always()
      run: |
        echo "📊 Generating enhanced deployment report..."
        
        cat > deployment_report.md << 'EOF'
        # Enhanced WhatsApp AI Bot Deployment Report
        
        **Deployment Time:** $(date)
        **Workflow Run:** ${{ github.run_number }}
        **Commit:** ${{ github.sha }}
        
        ## 🚀 Enhanced Features Deployed
        
        ✅ **Streaming AI Models** - DialoGPT with memory optimization
        ✅ **Advanced Personality** - Take-charge, humorous, engaging
        ✅ **Voice Processing** - Speech-to-text and text-to-speech
        ✅ **Meme Generation** - Custom meme creation with templates
        ✅ **Web Search** - Privacy-focused Whoogle integration
        ✅ **Auto-Reply Learning** - User pattern analysis
        ✅ **Proactive Messaging** - Context-aware suggestions
        ✅ **ASCII Art Generation** - Text-based art creation
        ✅ **Story Generation** - Interactive narrative creation
        ✅ **Translation Services** - Multi-language support
        ✅ **Chat Analysis** - Conversation pattern insights
        
        ## 🔧 Technical Optimizations
        
        ✅ **Disk Space Cleanup** - Freed ~20GB for AI models
        ✅ **Streaming Architecture** - No model persistence
        ✅ **Memory Management** - Efficient resource usage
        ✅ **5-Hour Auto-Loop** - Continuous deployment
        ✅ **Graceful Error Handling** - Robust failure recovery
        ✅ **Performance Monitoring** - Real-time health checks
        
        ## 📱 WhatsApp Integration
        
        ✅ **Enhanced Baileys Bridge** - Improved connection stability
        ✅ **QR Code Authentication** - First-time setup support
        ✅ **Message Queue System** - Reliable message processing
        ✅ **Auto-Reconnection** - Network interruption recovery
        ✅ **AI Message Indicators** - Clear bot identification
        
        ## 🎯 Next Steps
        
        1. Scan QR code to connect WhatsApp Web
        2. Send `!help` to see all available commands
        3. Try features: `!joke`, `!meme Hello World`, `!search AI news`
        4. Enable auto-reply: `!autoreply on`
        5. Request proactive messages for full experience
        
        **Bot Status:** Ready for deployment and user interaction!
        EOF
        
        echo "📋 Deployment report generated"
        
        # Display final status
        echo ""
        echo "🎉 ENHANCED WHATSAPP AI BOT DEPLOYMENT COMPLETE"
        echo "================================================"
        echo ""
        echo "🤖 Features: Take-charge personality, streaming AI, voice, memes, search"
        echo "📱 Platform: WhatsApp Web via enhanced Baileys integration"  
        echo "🔄 Auto-Loop: Every 5 hours with 4.5h runtime"
        echo "💾 Optimization: Memory-efficient streaming, no model persistence"
        echo ""
        echo "Ready for WhatsApp QR code scanning and user interaction!"
        echo ""