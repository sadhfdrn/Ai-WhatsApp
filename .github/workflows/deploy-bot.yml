name: Deploy WhatsApp AI Bot

on:
  schedule:
    # Run every 5 hours (GitHub Actions has a maximum runtime of 6 hours for free accounts)
    - cron: '0 */5 * * *'
  workflow_dispatch:
    # Allow manual trigger
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - '.github/workflows/deploy-bot.yml'

env:
  PYTHON_VERSION: '3.9'

jobs:
  deploy-bot:
    runs-on: ubuntu-latest
    timeout-minutes: 290  # 4h 50m to leave buffer before 5h limit
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1  # Shallow clone

    - name: Free up disk space
      run: |
        echo "üßπ Freeing up disk space..."
        df -h
        
        # Remove unnecessary packages and files
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo rm -rf /opt/hostedtoolcache/CodeQL
        sudo rm -rf /usr/local/share/boost
        sudo rm -rf /usr/local/graalvm/
        sudo rm -rf /usr/local/.ghcup/
        sudo rm -rf /usr/local/share/powershell
        sudo rm -rf /usr/local/share/chromium
        sudo rm -rf /usr/local/lib/node_modules
        sudo rm -rf /usr/share/swift
        sudo rm -rf /usr/local/share/vcpkg
        
        # Remove specific packages
        sudo apt-get remove -y '^dotnet-.*' '^llvm-.*' 'php.*' 'mysql-.*' 'mongodb-.*'
        sudo apt-get remove -y azure-cli google-cloud-sdk hhvm google-chrome-stable firefox
        sudo apt-get remove -y powershell mono-devel aspnetcore-*
        
        # Clean package cache
        sudo apt-get autoremove -y
        sudo apt-get autoclean -y
        sudo apt-get clean
        
        # Clear package lists
        sudo rm -rf /var/lib/apt/lists/*
        
        # Clean temporary files
        sudo rm -rf /tmp/*
        sudo rm -rf /var/tmp/*
        
        # Clean logs
        sudo journalctl --vacuum-time=1d
        
        # Clean snap packages
        sudo snap list --all | awk '/disabled/{print $1, $3}' | while read snapname revision; do
            sudo snap remove "$snapname" --revision="$revision"
        done
        
        echo "üìä Disk space after cleanup:"
        df -h

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install system dependencies
      run: |
        echo "üì¶ Installing system dependencies..."
        sudo apt-get update -qq
        
        # Audio processing dependencies
        sudo apt-get install -y --no-install-recommends \
          ffmpeg \
          libsndfile1 \
          portaudio19-dev \
          espeak-ng \
          espeak-ng-data \
          libespeak-ng-dev
        
        # Clean up after installation
        sudo apt-get clean
        sudo rm -rf /var/lib/apt/lists/*

    - name: Install Python dependencies
      run: |
        echo "üêç Installing Python dependencies..."
        python -m pip install --upgrade pip
        
        # Install core dependencies with optimizations
        pip install --no-cache-dir \
          python-dotenv==1.0.0 \
          requests==2.31.0 \
          beautifulsoup4==4.12.2 \
          trafilatura==1.6.4 \
          Pillow==10.1.0 \
          gtts==2.4.0 \
          psutil==5.9.6
        
        # Install AI/ML dependencies with memory optimization
        pip install --no-cache-dir \
          torch==2.1.0 --index-url https://download.pytorch.org/whl/cpu \
          transformers==4.35.0 \
          accelerate==0.24.1 \
          speechrecognition==3.10.0 \
          pydub==0.25.1
        
        # Install WhatsApp library (simulated - in real implementation use baileys-mod equivalent)
        echo "üì± WhatsApp integration ready"

    - name: Setup Whoogle Search Instance
      run: |
        echo "üîç Setting up Whoogle search..."
        
        # Install Whoogle dependencies
        pip install --no-cache-dir flask==3.0.0 requests==2.31.0
        
        # Create simple Whoogle mock for testing
        cat > whoogle_mock.py << 'EOF'
        from flask import Flask, request, jsonify
        import requests
        import re
        
        app = Flask(__name__)
        
        @app.route('/search')
        def search():
            query = request.args.get('q', '')
            # Simple search simulation - in production use actual Whoogle
            return f"""
            <html>
            <body>
            <div class="g">
                <h3><a href="https://example.com">Example Result for: {query}</a></h3>
                <span class="st">This is a sample search result for the query: {query}</span>
            </div>
            </body>
            </html>
            """
        
        @app.route('/health')
        def health():
            return jsonify({"status": "healthy"})
        
        if __name__ == '__main__':
            app.run(host='0.0.0.0', port=5001, debug=False)
        EOF
        
        # Start Whoogle mock in background
        python whoogle_mock.py &
        echo "‚úÖ Whoogle search instance started"

    - name: Optimize Python for memory usage
      run: |
        echo "üîß Optimizing Python for memory usage..."
        
        # Set Python optimization flags
        export PYTHONOPTIMIZE=2
        export PYTHONDONTWRITEBYTECODE=1
        export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
        
        # Configure transformers for streaming
        export TRANSFORMERS_CACHE=/tmp/transformers_cache
        export HF_HOME=/tmp/huggingface_cache
        
        # Set memory optimization flags
        export TOKENIZERS_PARALLELISM=false
        
        echo "Environment variables set for optimization"

    - name: Create bot configuration
      run: |
        echo "‚öôÔ∏è Creating bot configuration..."
        
        # Create .env file with configuration
        cat > .env << EOF
        # WhatsApp Configuration
        WHATSAPP_CREDS=${{ secrets.WHATSAPP_CREDS }}
        BOT_NAME=AI Assistant ü§ñ
        BOT_PREFIX=!
        
        # AI Model Configuration
        AI_MODEL=microsoft/DialoGPT-small
        MAX_RESPONSE_LENGTH=500
        TEMPERATURE=0.8
        USE_STREAMING=true
        
        # Voice Configuration
        TTS_LANGUAGE=en
        VOICE_ENABLED=true
        VOICE_SPEED=1.0
        
        # Web Search Configuration
        WHOOGLE_URL=http://localhost:5001
        SEARCH_ENABLED=true
        MAX_SEARCH_RESULTS=5
        
        # Auto-reply Configuration
        AUTO_REPLY_ENABLED=false
        AUTO_REPLY_DELAY_MIN=5
        AUTO_REPLY_DELAY_MAX=15
        
        # Personality Configuration
        PERSONALITY_MODE=humorous
        JOKE_FREQUENCY=0.3
        PROACTIVE_MESSAGING=false
        
        # Feature Toggles
        MEME_GENERATION=true
        ASCII_ART=true
        TRANSLATION=true
        CHAT_ANALYSIS=true
        
        # GitHub Actions Configuration
        GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}
        WORKFLOW_TIMEOUT=18000
        
        # Resource Optimization
        LOW_MEMORY_MODE=true
        CACHE_SIZE=50
        EOF
        
        echo "‚úÖ Configuration created"

    - name: Pre-download AI models
      run: |
        echo "üß† Pre-downloading AI models..."
        
        # Create model download script
        cat > download_models.py << 'EOF'
        import os
        os.environ['TRANSFORMERS_OFFLINE'] = '0'
        
        from transformers import AutoTokenizer, AutoModel
        import torch
        
        try:
            model_name = "microsoft/DialoGPT-small"
            print(f"Downloading {model_name}...")
            
            # Download with streaming optimization
            tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir="/tmp/transformers_cache",
                low_cpu_mem_usage=True
            )
            
            model = AutoModel.from_pretrained(
                model_name,
                cache_dir="/tmp/transformers_cache",
                low_cpu_mem_usage=True,
                torch_dtype=torch.float16,
                device_map="auto"
            )
            
            print("‚úÖ Model downloaded successfully")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Model download warning: {e}")
            print("Bot will work in limited mode")
        EOF
        
        timeout 300 python download_models.py || echo "‚ö†Ô∏è Model download timeout, continuing..."

    - name: Run WhatsApp AI Bot
      timeout-minutes: 280  # 4h 40m timeout
      run: |
        echo "üöÄ Starting WhatsApp AI Bot..."
        echo "Bot will run for approximately 4 hours and 40 minutes"
        echo "Start time: $(date)"
        
        # Set memory limits
        export PYTHONOPTIMIZE=2
        export PYTHONDONTWRITEBYTECODE=1
        export TRANSFORMERS_OFFLINE=1
        
        # Monitor system resources
        python -c "
        import psutil
        import os
        print(f'üíæ Available memory: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f} GB')
        print(f'üíΩ Available disk: {psutil.disk_usage(\"/\").free / 1024 / 1024 / 1024:.1f} GB')
        print(f'üîß CPU count: {psutil.cpu_count()}')
        print(f'üìä Process ID: {os.getpid()}')
        "
        
        # Start the bot with error handling
        python -u main.py || {
          echo "‚ùå Bot crashed, attempting restart..."
          sleep 30
          python -u main.py
        }

    - name: Cleanup and prepare for next run
      if: always()
      run: |
        echo "üßπ Cleaning up for next run..."
        
        # Log final statistics
        echo "üìä Final system stats:"
        df -h
        free -h
        
        # Clean temporary files
        rm -rf /tmp/transformers_cache/* 2>/dev/null || true
        rm -rf /tmp/huggingface_cache/* 2>/dev/null || true
        rm -rf __pycache__ 2>/dev/null || true
        rm -rf .pytest_cache 2>/dev/null || true
        
        # Clean Python cache
        find . -type f -name "*.pyc" -delete 2>/dev/null || true
        find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
        
        echo "End time: $(date)"
        echo "‚úÖ Cleanup completed"

    - name: Schedule next run
      if: always()
      run: |
        echo "‚è∞ Next scheduled run will be in 5 hours"
        echo "Current time: $(date)"
        echo "Next run: $(date -d '+5 hours')"
        
        # Log run statistics
        echo "üìà Run Statistics:" >> bot_stats.log
        echo "Run completed at: $(date)" >> bot_stats.log
        echo "Duration: Approximately 5 hours" >> bot_stats.log
        echo "Status: ${{ job.status }}" >> bot_stats.log
        echo "---" >> bot_stats.log
        
        # Keep only last 10 runs in log
        tail -50 bot_stats.log > temp_stats.log && mv temp_stats.log bot_stats.log || true

  # Monitor job to restart if it fails
  monitor:
    needs: deploy-bot
    runs-on: ubuntu-latest
    if: failure()
    
    steps:
    - name: Log failure and prepare restart
      run: |
        echo "‚ö†Ô∏è Bot deployment failed, will retry on next schedule"
        echo "Failed at: $(date)"
        echo "Next scheduled attempt: $(date -d '+5 hours')"
        
        # In a production environment, you might want to:
        # 1. Send notifications about the failure
        # 2. Log the failure reason
        # 3. Implement exponential backoff for retries
        # 4. Check system status before next run

# Workflow will automatically re-run every 5 hours due to the cron schedule
# This creates a continuous loop while respecting GitHub Actions free tier limits
